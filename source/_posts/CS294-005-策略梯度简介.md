---
title: CS294-005-策略梯度简介
mathjax: true
date: 2019-09-18 21:24:53
categories: RL(CS294)
tags: RL
---

### 直接策略梯度推导

强化学习的目标为找出最优的策略，使得期望收益最大。
$$
\theta^* = arg\max_\theta J(\theta) = arg \max_\theta E_{\tau\sim p_\theta(\tau)}[r(\tau)]
$$
对$J(\theta)$进行求导可得
$$
\begin{aligned}
\bigtriangledown_\theta J(\theta) &=\bigtriangledown_\theta  E_{\tau\sim p_\theta(\tau)}[r(\tau)]\\
&= \bigtriangledown_\theta\int p_\theta(\tau)r(\tau)d\tau\\
&=\int \bigtriangledown_\theta p_\theta(\tau) r(\tau)d\tau \\
&=\int p_\theta(\tau)\bigtriangledown_\theta log\,p_\theta(\tau) r(\tau)d\tau\\
&= E_{\tau\sim p_\theta(\tau)}[\bigtriangledown_\theta log\,p_\theta(\tau)r(\tau)]
\end{aligned}
$$
由$p_\theta(\tau)$展开式可得
$$
\begin{aligned}
p_\theta(\tau) &= p(s_1) \prod_{t=1}^T \pi_\theta(a_t|s_t)p(s_{t+1}|s_t, a_t) \\
log\,p_\theta(\tau) &= log \,p(s_1) + \sum_{t=1}^T log\,\pi_\theta(a_t|s_t) + log\,p(s_{t+1}|s_t,a_t)\\
\bigtriangledown_\theta log\,p_\theta(\tau) &=  \sum_{t=1}^T \bigtriangledown_\theta log \pi_\theta(a_t|s_t)
\end{aligned}
$$
故化简后得到的$J(\theta)$的梯度表达式为
$$
\bigtriangledown_\theta J(\theta) = E_{\tau\sim p_\theta(\tau)}[(\sum_{t=1}^T \bigtriangledown_\theta log\,\pi_\theta(a_t|s_t))](\sum_{t=1}^T r(s_t, a_t))
$$
根据采样值来逼近期望值可以得到
$$
\bigtriangledown_\theta J(\theta) =\frac{1}{N}\sum_{i=1}^N[(\sum_{t=1}^T \bigtriangledown_\theta log\,\pi_\theta(a_t|s_t))](\sum_{t=1}^T r(s_t, a_t))
$$
